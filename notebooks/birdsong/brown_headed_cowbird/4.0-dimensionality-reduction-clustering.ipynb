{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Perform Dimensionality Reduction\n",
    "- For each bird included in audio dataset.\n",
    "- Using UMAP as preprocessing step for density-based clustering.\n",
    "- HDBSCAN for data clustering (in combination with UMAP), with (1) how close points should be to each other to be considered a part of a cluster, (2) minimum number of points to form a dense region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T23:53:17.039691Z",
     "start_time": "2018-10-22T23:53:13.738894Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'umap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-56f0e0549169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdbscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mumap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'umap'"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline  \n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from skimage.transform import resize\n",
    "\n",
    "import hdbscan \n",
    "import umap\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T23:53:17.414930Z",
     "start_time": "2018-10-22T23:53:17.041615Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.network_analysis.network_analysis import cluster_data, split_times_into_seqs, syllables_to_sequences, draw_transition_diagram\n",
    "#import avgn.network.convnet_model as conv\n",
    "from avgn.network.training import load_from_hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T23:53:17.419937Z",
     "start_time": "2018-10-22T23:53:17.417357Z"
    }
   },
   "outputs": [],
   "source": [
    "dims = [128, 128, 1] # first dimension of input data\n",
    "batch_size = 16 # size of batches to use (per GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T23:53:17.509996Z",
     "start_time": "2018-10-22T23:53:17.421915Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T23:55:33.740681Z",
     "start_time": "2018-10-22T23:55:33.736361Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: FIX IMPORTS (ALSO FOR BIRDSONG)\n",
    "hdf_locs = glob('../../../../BirdsongAE/data/syllables_datasets/BF/Bird*')\n",
    "hdf_locs = glob('../../../data/bf_song_syllables/BF/Bird*_'+str(dims[0])+'.hdf5')\n",
    "hdf_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T23:55:34.658396Z",
     "start_time": "2018-10-22T23:55:34.654484Z"
    }
   },
   "outputs": [],
   "source": [
    "# What information is stored in the HDF5 file\n",
    "now_string = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") # this is used to identify this training instance\n",
    "to_load = ['spectrograms', 'lengths', 'start', 'wav_file', 'syll_start_rel_wav']\n",
    "nex=32 # for plotting\n",
    "cluster_pct = 0.025 # we set the minimum cluster size at 0.25% of the dataset ()\n",
    "# make sequence df\n",
    "\n",
    "max_timedelta = 10. # seconds # maximum amount of time allowed to pass before considering this bout new\n",
    "seq_len_cutoff = 2 # syllables/units # minimum amount of syllables/units allowed to be considered part of a sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-22T23:55:34.837091Z",
     "start_time": "2018-10-22T23:55:34.832008Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_with_labels(data, labels, title = '', ax = None, figsize = (9,9)):\n",
    "    palette = sns.color_palette('husl', len(np.unique(labels)))\n",
    "    labs_to_numbers_dict = {l:i for i,l in enumerate(np.unique(labels))}\n",
    "    np.random.shuffle(palette)\n",
    "    colors = [palette[labs_to_numbers_dict[x]] if x >= 0 else (0.75, 0.75, 0.75) for x in np.array(labels)]\n",
    "\n",
    "    if not ax: fig, ax= plt.subplots(nrows=1,ncols=1,figsize=figsize)\n",
    "    ax.scatter(data.T[0], data.T[1],\n",
    "               color=colors, alpha = 1, linewidth= 0, s=5)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(title)\n",
    "    if not ax: plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T00:05:52.063123Z",
     "start_time": "2018-10-22T23:55:39.277911Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for loc in hdf_locs:\n",
    "    species = 'cb'\n",
    "    all_content = load_from_hdf5([loc], to_load)\n",
    "    num_examples = len(all_content['name'])\n",
    "    bird = loc.split('/')[-1].split('_')[0]\n",
    "    if num_examples < 5000: continue \n",
    "    # visualize\n",
    "    print(bird, num_examples)\n",
    "    for j in range(5):\n",
    "        fig, ax = plt.subplots(nrows=1,ncols=nex, figsize=(nex,1))\n",
    "        for i in range(nex):ax[i].matshow(all_content['spectrograms'][np.random.randint(num_examples)].reshape((dims[0],dims[1])),\n",
    "                      cmap=plt.cm.viridis, interpolation='nearest', origin='lower');ax[i].axis('off'); \n",
    "        plt.show()\n",
    "        \n",
    "    # embed x to z\n",
    "    x = all_content['spectrograms']\n",
    "    x_small = [resize(i, [16,16]) for i in tqdm(x)]\n",
    "    x_small = np.array(x_small).reshape((len(x_small), np.prod(np.shape(x_small)[1:])))\n",
    "    x_small = [(i*255).astype('uint8') for i in x_small]\n",
    "    \n",
    "    clusterable_embedding = umap.UMAP(\n",
    "        n_neighbors=30,\n",
    "        #min_dist=0.0,\n",
    "        n_components=2,\n",
    "        random_state=42,\n",
    "    ).fit_transform(x_small)\n",
    "\n",
    "    # prepare dataframe\n",
    "    BirdData = pd.DataFrame({\n",
    "            'specs':all_content['spectrograms'].tolist(), \n",
    "            'z':clusterable_embedding.tolist(),\n",
    "            'syllable_time': [datetime.strptime(i[0], '%d/%m/%y %H:%M:%S.%f') for i in all_content['start'].astype('str').tolist()] , \n",
    "            'syll_length_s': all_content['lengths'].tolist(), \n",
    "            'start_time_rel_wav': all_content['syll_start_rel_wav'].tolist(), \n",
    "            'original_wav': all_content['wav_file'].tolist(), \n",
    "        })\n",
    "\n",
    "    min_cluster_size = int(num_examples*cluster_pct)\n",
    "    \n",
    "    # cluster z\n",
    "    BirdData['labels'] = cluster_data(np.array(list(BirdData.z.values)),\n",
    "                              hdbscan.HDBSCAN,\n",
    "                              (),\n",
    "                              {'min_cluster_size':min_cluster_size,  'min_samples':1},\n",
    "                             verbose = True)\n",
    "\n",
    "    # check how many syllables were labelled\n",
    "    pct_unlabelled = np.sum(BirdData['labels'] == -1)/len(BirdData['labels'])\n",
    "    print(str(round(pct_unlabelled*100,1))+ '% of syllables went unlabelled')\n",
    "\n",
    "    # plot clusters\n",
    "    plot_with_labels(np.array(list(BirdData.z.values)), BirdData['labels'].values, figsize=(20,20))\n",
    "\n",
    "    # Add sequence information to bird dataframe\n",
    "    BirdData = split_times_into_seqs(BirdData, max_timedelta, seq_len_cutoff)\n",
    "\n",
    "    # create a dataset of sequences\n",
    "    sequence_df = syllables_to_sequences( BirdData, ['labels','z','original_wav', 'specs','start_time_rel_wav','syll_length_s']).rename(columns={'labels': 'sequence'})\n",
    "    sequence_df['lens'] = [len(i) for i in sequence_df.sequence.values]\n",
    "\n",
    "    network_identifier = bird+'_umap'\n",
    "\n",
    "    ### Save the sequence dataframe\n",
    "    sequence_df_loc = '../../../data/sequence_df/'+'/'+species+'/'+network_identifier+'/'+now_string+'/'\n",
    "    sequence_df_name = now_string+'.pickle'\n",
    "    if not os.path.exists(sequence_df_loc):\n",
    "        os.makedirs(sequence_df_loc) \n",
    "    sequence_df.to_pickle(sequence_df_loc+sequence_df_name)\n",
    "\n",
    "    draw_transition_diagram(sequence_df['z'].values, num_ex=len(sequence_df), alpha=.025, linewidth=1, cmap=plt.get_cmap('cubehelix'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: figure out clustering and vizualization (ie. what do they do?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
