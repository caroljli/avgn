{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Train Autoencoder Network\n",
    "This notebook trains a convolutional autoencoder on the hdf5 dataset created by the syllable segmentation notebooks. \n",
    "- The trained model is then used to perform dimensionality reduction and generate novel stimuli.\n",
    "- Neural net from repo in files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:16:59.067995Z",
     "start_time": "2018-10-23T02:16:54.357625Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/caroljli/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/caroljli/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/caroljli/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/home/caroljli/anaconda3/lib/python3.7/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/caroljli/anaconda3/lib/python3.7/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libcublas.so.10.0: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fd50fcc8758f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline  '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Protocol buffers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/home/caroljli/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/home/caroljli/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/home/caroljli/.local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/home/caroljli/anaconda3/lib/python3.7/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/home/caroljli/anaconda3/lib/python3.7/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: libcublas.so.10.0: cannot open shared object file: No such file or directory\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline  \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import hdbscan \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:16:59.742542Z",
     "start_time": "2018-10-23T02:16:59.070426Z"
    }
   },
   "outputs": [],
   "source": [
    "from avgn.network_analysis.network_analysis import *\n",
    "import avgn.network.convnet_model as conv\n",
    "from avgn.network.training import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocate GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:16:59.749959Z",
     "start_time": "2018-10-23T02:16:59.745670Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = [3] # set CUDA to see one GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=','.join([str(i) for i in gpus])\n",
    "num_gpus = len(gpus) # number of GPUs to use\n",
    "if len(gpus) < 1:\n",
    "    num_gpus = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:01.888555Z",
     "start_time": "2018-10-23T02:16:59.752016Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "print( [x.name for x in local_device_protos if x.device_type == 'GPU'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:01.892912Z",
     "start_time": "2018-10-23T02:17:01.890467Z"
    }
   },
   "outputs": [],
   "source": [
    "dims = [128, 128, 1] # first dimension of input data\n",
    "batch_size = 16 # size of batches to use (per GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:02.051683Z",
     "start_time": "2018-10-23T02:17:01.894613Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:02.235239Z",
     "start_time": "2018-10-23T02:17:02.144798Z"
    }
   },
   "outputs": [],
   "source": [
    "# bird_name = 'CAVI' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:02.313814Z",
     "start_time": "2018-10-23T02:17:02.237212Z"
    }
   },
   "outputs": [],
   "source": [
    "hdf_locs = glob('../../../data/bf_song_syllables/BF/*_'+str(dims[0])+'.hdf5')\n",
    "hdf_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:02.448245Z",
     "start_time": "2018-10-23T02:17:02.315556Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_from_hdf5(hdf_locs, to_load, minsize=2500):\n",
    "    \"\"\"Loads content from a list of HDF5 files\"\"\"\n",
    "    hdf5_content = {}\n",
    "    first_item=True\n",
    "    for i, folder in enumerate(hdf_locs):\n",
    "        with h5py.File(folder,'r') as hf:\n",
    "            print(folder, len(hf[to_load[0]].value))\n",
    "            if len(hf[to_load[0]].value) < minsize: continue\n",
    "            if first_item:\n",
    "                for tl in to_load:\n",
    "                    hdf5_content[tl] = hf[tl].value\n",
    "                hdf5_content['name'] = np.repeat(list(hf.attrs.values())[0], np.shape(hf['spectrograms'].value)[0])\n",
    "                first_item=False\n",
    "            else:\n",
    "                for tl in to_load:\n",
    "                    hdf5_content[tl] = np.append(hdf5_content[tl], hf[tl].value, axis = 0)\n",
    "                hdf5_content['name'] = np.append(hdf5_content['name'], np.repeat(list(hf.attrs.values())[0], np.shape(hf['spectrograms'].value)[0]))\n",
    "    return hdf5_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:02.538333Z",
     "start_time": "2018-10-23T02:17:02.450143Z"
    }
   },
   "outputs": [],
   "source": [
    "# What information is stored in the HDF5 file\n",
    "to_load = ['spectrograms', 'lengths', 'start', 'wav_file', 'syll_start_rel_wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:31.170038Z",
     "start_time": "2018-10-23T02:17:02.540112Z"
    }
   },
   "outputs": [],
   "source": [
    "all_content = load_from_hdf5(hdf_locs, to_load)\n",
    "num_examples = len(all_content['name'])\n",
    "num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:34.131493Z",
     "start_time": "2018-10-23T02:17:31.172305Z"
    }
   },
   "outputs": [],
   "source": [
    "nex=20\n",
    "for i in range(3):\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=nex, figsize=(nex,1))\n",
    "    for i in range(nex):\n",
    "        ax[i].matshow(all_content['spectrograms'][np.random.randint(len(all_content['spectrograms']))].reshape((dims[0],dims[1])),\n",
    "                      cmap=plt.cm.viridis, interpolation='nearest', origin='lower')\n",
    "        ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into training and validation sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:34.136150Z",
     "start_time": "2018-10-23T02:17:34.133648Z"
    }
   },
   "outputs": [],
   "source": [
    "val_pct = .1 # how much of the dataset to set aside for validation of reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:35.193727Z",
     "start_time": "2018-10-23T02:17:34.138032Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_set = np.random.permutation(np.arange(len(all_content['spectrograms'])))[:int(len(all_content['spectrograms'])*val_pct)]\n",
    "mask = np.ones(len(all_content['spectrograms']), np.bool)\n",
    "mask[validation_set] = 0\n",
    "validation_syllables = all_content['spectrograms'][validation_set]\n",
    "training_syllables = all_content['spectrograms'][mask]\n",
    "print(len(training_syllables), len(validation_syllables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the network\n",
    "- Network dimensions.\n",
    "- Saving network conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:35.201573Z",
     "start_time": "2018-10-23T02:17:35.195646Z"
    }
   },
   "outputs": [],
   "source": [
    "# dimensions of network\n",
    "# [depth, filter size, stride] # decoder will become inverse of encoder\n",
    "encoder_dims = [\n",
    "    [64, 3, 1],  # 64\n",
    "    [64, 3, 2], # 64\n",
    "    [128, 3, 1], # 64\n",
    "    [64, 3, 2], # 32\n",
    "    [128, 3, 1], # 32\n",
    "    [64, 3, 2], # 16\n",
    "    [128, 3, 1], # 16\n",
    "    [2000, 0, 0], # 8\n",
    "    [2000, 0, 0], # 8\n",
    "]\n",
    "decoder_dims = encoder_dims[::-1]\n",
    "hidden_size = 2\n",
    "latent_loss = 'distance' # Either 'None', 'distance', or 'VAE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:35.299261Z",
     "start_time": "2018-10-23T02:17:35.203314Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a unique key (e.g. datetime) for this training instance\n",
    "network_identifier = 'Distance_AE_'+bird_name\n",
    "now_string = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") # this is used to identify this training instance\n",
    "print(now_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:35.390446Z",
     "start_time": "2018-10-23T02:17:35.301128Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:35.497143Z",
     "start_time": "2018-10-23T02:17:35.392271Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network_identifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2204548894aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparam_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../../data/network_params/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnetwork_identifier\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_loc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnow_string\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_params.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'network_identifier' is not defined"
     ]
    }
   ],
   "source": [
    "# save params\n",
    "param_loc = '../../../data/network_params/'+network_identifier+'/'\n",
    "print(param_loc+now_string+'_params.pickle')\n",
    "if not os.path.exists(param_loc):\n",
    "                os.makedirs(param_loc) \n",
    "with open(param_loc+now_string+'_params.pickle', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([encoder_dims, decoder_dims, hdf_locs, dims, batch_size, hidden_size, validation_set, latent_loss], f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:48.396830Z",
     "start_time": "2018-10-23T02:17:35.499022Z"
    }
   },
   "outputs": [],
   "source": [
    "model = conv.ConvAE(dims, batch_size, encoder_dims, decoder_dims, hidden_size, latent_loss=latent_loss, network_type='AE', gpus=[0], adam_eps = 1.0e-8, activation_fn=tf.nn.relu) # eps = 0.1 and lr = 1 (after lr 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:48.401788Z",
     "start_time": "2018-10-23T02:17:48.399032Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a training iterator over your data\n",
    "iter_ = data_iterator(training_syllables,y=None,batch_size=batch_size,num_gpus=num_gpus,dims=dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:52.168748Z",
     "start_time": "2018-10-23T02:17:48.403469Z"
    }
   },
   "outputs": [],
   "source": [
    "nex=16\n",
    "\n",
    "for ii in range(5):\n",
    "    example_data = iter_.__next__()[0]\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=nex, figsize=(nex*2,1*2))\n",
    "    for i in range(nex):\n",
    "        ax[i].matshow(example_data[i].reshape((dims[0],dims[1])), cmap=plt.cm.viridis, interpolation='nearest', origin='lower', vmin=0, vmax=1)\n",
    "        ax[i].axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Single Epoch\n",
    "To test; generative network in files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:17:52.173470Z",
     "start_time": "2018-10-23T02:17:52.170900Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "latent_loss_weights = 1e-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:18:35.938653Z",
     "start_time": "2018-10-23T02:17:52.175197Z"
    }
   },
   "outputs": [],
   "source": [
    "# a list of which tensors to return from the network (e.g. train_D/G are necessary to train the network, losses are useful for plots)\n",
    "return_list = ['train_D', 'train_E', 'L_d', 'L_e', 'recon_loss', 'distance_loss'] \n",
    "iter_ = data_iterator(training_syllables,y=None,batch_size=batch_size,num_gpus=num_gpus,dims=dims)\n",
    "validation_iter_ = data_iterator(validation_syllables,y=None,batch_size=batch_size,num_gpus=num_gpus,dims=dims)\n",
    "\n",
    "#train_AE(model, iter_,dataset_size = len(training_syllables), validation_iter_=False, learning_rate = 1.0, return_list=return_list)\n",
    "training_df, validation_df = train_AE(model, iter_,dataset_size = int(len(training_syllables)/100), validation_iter_=validation_iter_,validation_size=len(validation_syllables),\n",
    "                                      learning_rate = learning_rate, return_list=return_list, latent_loss_weights=latent_loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:18:35.957765Z",
     "start_time": "2018-10-23T02:18:35.940868Z"
    }
   },
   "outputs": [],
   "source": [
    "training_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Entire Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:18:36.083010Z",
     "start_time": "2018-10-23T02:18:35.959644Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:18:36.176649Z",
     "start_time": "2018-10-23T02:18:36.084961Z"
    }
   },
   "outputs": [],
   "source": [
    "### Parameters, etc...\n",
    "num_epochs = 50 # how many epochs to train the network for\n",
    "epoch = 0 # initialize epochs\n",
    "save_loc = '../../../data/models/'+network_identifier + '/'+now_string+'/'\n",
    "print(save_loc)\n",
    "# Visualizations (these only work if you choose a 2D latent space - write a new viz function if you didn't...)\n",
    "network_save_epochs = np.unique(np.logspace(0,np.log2(num_epochs),num=20, base= 2).astype('int')) # (epochs) - which epochs to save the network\n",
    "network_save_epochs=network_save_epochs[network_save_epochs>50]\n",
    "#network_visualize_progress = np.unique(np.logspace(0,np.log2(num_epochs),num=10000, base= 2).astype('int')) # how often to visualize the network (leave empty list for never)\n",
    "network_visualize_progress = np.arange(num_epochs)\n",
    "img_save_loc = '../../../img/'+network_identifier + '/'+now_string+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T02:18:36.250126Z",
     "start_time": "2018-10-23T02:18:36.178508Z"
    }
   },
   "outputs": [],
   "source": [
    "#model.load_network('../../../../data/models/Distance_AE_CAVI/2018-10-17_10-00-27/28_model.tfmod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-23T02:16:53.950Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for epoch in tqdm(range(epoch,num_epochs)):\n",
    "        \n",
    "        \n",
    "        # visualization\n",
    "        if epoch in network_visualize_progress:\n",
    "            clear_output()\n",
    "            print(epoch)\n",
    "            visualize_2D_AE(model, training_df, validation_df, example_data, num_examples,\n",
    "                            batch_size, num_gpus, dims, iter_, n_cols = 4, std_to_plot = 2.5,\n",
    "                            save_loc = img_save_loc+now_string+'/'+str(epoch)+'.jpg')\n",
    "        \n",
    "        # training\n",
    "        iter_ = data_iterator(training_syllables,y=None,batch_size=batch_size,num_gpus=num_gpus,dims=dims)\n",
    "        validation_iter_ = data_iterator(validation_syllables,y=None,batch_size=batch_size,num_gpus=num_gpus,dims=dims)\n",
    "        training_df_epoch, validation_df_epoch = train_AE(model, iter_, dataset_size = len(training_syllables),\n",
    "                                              validation_iter_=validation_iter_,validation_size=len(validation_syllables),\n",
    "                                              learning_rate = learning_rate, return_list=return_list,\n",
    "                                                         latent_loss_weights=latent_loss_weights)\n",
    "        training_df = pd.concat([training_df, training_df_epoch])\n",
    "        validation_df = pd.concat([validation_df, validation_df_epoch])\n",
    "        \n",
    "        # save network\n",
    "        if epoch in network_visualize_progress:\n",
    "            if not os.path.exists(save_loc):\n",
    "                os.makedirs(save_loc) \n",
    "            model.save_network(save_loc+str(epoch)+'_model.tfmod')\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('interrupted by keyboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T19:33:42.692814Z",
     "start_time": "2018-10-23T19:33:42.689769Z"
    }
   },
   "outputs": [],
   "source": [
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T19:36:59.294028Z",
     "start_time": "2018-10-23T19:36:19.986526Z"
    }
   },
   "outputs": [],
   "source": [
    "### save this model\n",
    "if not os.path.exists(save_loc+'manual/'):\n",
    "    os.makedirs(save_loc+'manual/') \n",
    "model.save_network(save_loc+'manual/manual_model.tfmod')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate Syllables in Latent Space\n",
    "- Encodes and decodes syllables in neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:01:22.829868Z",
     "start_time": "2018-10-23T20:01:22.812738Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_x(x, z_shape,batch_size):\n",
    "    nex =np.ceil(len(x)/batch_size).astype('int')\n",
    "    face_z = np.zeros([nex*batch_size] + list(z_shape))\n",
    "    face_x = np.zeros([nex*batch_size] + list(np.shape(x)[1:]))\n",
    "    face_x[:len(x)] = x\n",
    "    for batch in np.arange(nex):\n",
    "        cur_batch = face_x[int(batch*batch_size):int((batch+1)*batch_size)]\n",
    "        z_out = model.sess.run(model.z_x,{model.x_input: cur_batch})\n",
    "        face_z[batch*batch_size:(batch+1)*batch_size,:] = z_out\n",
    "    z_final = face_z[:len(x)]\n",
    "    return z_final\n",
    "\n",
    "def decode_z(z, x_shape, batch_size):\n",
    "    nex =np.ceil(len(z)/batch_size).astype('int')\n",
    "    face_x = np.zeros([nex*batch_size] + list(x_shape))\n",
    "    face_z = np.zeros([nex*batch_size] + list(np.shape(z)[1:]))\n",
    "    face_z[:len(z)] = z\n",
    "    for batch in np.arange(nex):\n",
    "        cur_batch = face_z[int(batch*batch_size):int((batch+1)*batch_size)]\n",
    "        x_out = model.sess.run(model.x_tilde,{model.z_x: cur_batch})\n",
    "        face_x[batch*batch_size:(batch+1)*batch_size,:] = x_out\n",
    "    x_final = face_x[:len(z)]\n",
    "    return x_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:02:51.543960Z",
     "start_time": "2018-10-23T20:01:23.298197Z"
    }
   },
   "outputs": [],
   "source": [
    "x = all_content['spectrograms']/255.\n",
    "z = encode_x(np.reshape(x, (len(x), np.prod(np.shape(x)[1:]))), [hidden_size], model.batch_size)\n",
    "print(np.shape(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:33:23.298298Z",
     "start_time": "2018-10-23T20:31:46.474509Z"
    }
   },
   "outputs": [],
   "source": [
    "BirdData = pd.DataFrame({\n",
    "        'specs':all_content['spectrograms'].tolist(), \n",
    "        'z':z.tolist(),\n",
    "        'syllable_time': [datetime.strptime(i[0], '%d/%m/%y %H:%M:%S.%f') for i in all_content['start'].astype('str').tolist()] , \n",
    "        'syll_length_s': all_content['lengths'].tolist(), \n",
    "        'start_time_rel_wav': all_content['syll_start_rel_wav'].tolist(), \n",
    "        'original_wav': all_content['wav_file'].tolist(), \n",
    "    })\n",
    "BirdData[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Vizualization Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:40:59.582770Z",
     "start_time": "2018-10-23T20:40:59.569494Z"
    }
   },
   "outputs": [],
   "source": [
    "np.min(z[:,0]), np.max(z[:,0]), np.min(z[:,1]), np.max(z[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:42:25.728444Z",
     "start_time": "2018-10-23T20:42:25.102850Z"
    }
   },
   "outputs": [],
   "source": [
    "spacing = 5\n",
    "xs = [-25, 25]\n",
    "ys = [-125,-75]\n",
    "xv,yv = draw_grid(model,dims,batch_size,xs,ys,spacing = spacing, zoom = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:42:28.649863Z",
     "start_time": "2018-10-23T20:42:27.428818Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(20,20))\n",
    "ax.scatter(z[:,0], z[:,1], color='k', s=1)\n",
    "ax.scatter(xv, yv, color='r', s=30)\n",
    "#ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syllable Interpolations\n",
    "- Generating novel syllables training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:42:47.052565Z",
     "start_time": "2018-10-23T20:42:47.047025Z"
    }
   },
   "outputs": [],
   "source": [
    "### choose two points\n",
    "# get their z values\n",
    "# interpolate between those z values\n",
    "# pass those z values into network (encode them)\n",
    "# plot a figure of this interpolation, save a gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:44:05.759611Z",
     "start_time": "2018-10-23T20:44:05.579362Z"
    }
   },
   "outputs": [],
   "source": [
    "pt1 = 55000; pt2 = 10000\n",
    "syllable_1 = all_content['spectrograms'][pt1]\n",
    "syllable_2= all_content['spectrograms'][pt2]\n",
    "fig, ax = plt.subplots(nrows=1,ncols=2, figsize=(6,3))\n",
    "ax[0].matshow(syllable_1, origin = 'lower'); ax[0].axis('off')\n",
    "ax[1].matshow(syllable_2, origin = 'lower'); ax[1].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:44:16.955377Z",
     "start_time": "2018-10-23T20:44:16.810993Z"
    }
   },
   "outputs": [],
   "source": [
    "n_frames_per_interp = 32 # how many points in interp.\n",
    "z1 = encode_x(np.array([syllable_1.flatten()/255.]), [2], batch_size)[0]\n",
    "z2 = encode_x(np.array([syllable_2.flatten()/255.]), [2], batch_size)[0]\n",
    "pcts = np.linspace(0,1,n_frames_per_interp+1)[:-1]\n",
    "interp_z = np.array([(z1*pct) + (z2*(1.-pct)) for pct in tqdm(pcts, leave=False)])\n",
    "x_interp = decode_z(interp_z, [np.prod(dims[:-1])], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:44:18.096615Z",
     "start_time": "2018-10-23T20:44:17.010148Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(10,10))\n",
    "ax.plot([z1[0],z2[0]], [z1[1],z2[1]], color='red', lw=5)\n",
    "ax.scatter(z[:,0], z[:,1], color='k', s=1, alpha=.2)\n",
    "\n",
    "#ax.scatter(xv, yv, color='r', s=30)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:44:20.270831Z",
     "start_time": "2018-10-23T20:44:18.098882Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1,ncols=n_frames_per_interp, figsize=(n_frames_per_interp*3,3))\n",
    "for frame in range(n_frames_per_interp):\n",
    "    ax[frame].matshow(np.squeeze(x_interp[frame].reshape(dims)), origin = 'lower')\n",
    "    ax[frame].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovering Audio Test\n",
    "- From generated syllable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:44:24.009936Z",
     "start_time": "2018-10-23T20:44:24.002334Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import avgn.spectrogramming.spectrogramming as sg\n",
    "import skimage.transform\n",
    "import IPython.display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:44:25.769793Z",
     "start_time": "2018-10-23T20:44:25.761026Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dictionary with spectrogram parameters\n",
    "dict_now_string = '2018-10-17_13-40-37'\n",
    "dict_loc = '../../../data/parameter_dictionaries/'+dict_now_string+'_dict.pickle'\n",
    "with open(dict_loc, 'rb') as f:\n",
    "    hparams = pickle.load(f)\n",
    "globals().update(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:44:25.944204Z",
     "start_time": "2018-10-23T20:44:25.925019Z"
    }
   },
   "outputs": [],
   "source": [
    "_mel_basis = sg._build_mel_basis(hparams) # build a basis function if you are using a mel spectrogram\n",
    "mel_inversion_filter = (_mel_basis.T / _mel_basis.sum(axis=1))\n",
    "mel_inversion_filter =np.nan_to_num(np.transpose(mel_inversion_filter / mel_inversion_filter.sum(axis=1)[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:44:26.069040Z",
     "start_time": "2018-10-23T20:44:26.063697Z"
    }
   },
   "outputs": [],
   "source": [
    "def rescale(X, out_min, out_max):\n",
    "    return out_min + (X - np.min(X)) * ((out_max - out_min) / (np.max(X) - np.min(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:44:26.225532Z",
     "start_time": "2018-10-23T20:44:26.212756Z"
    }
   },
   "outputs": [],
   "source": [
    "def invertSyllableToWav(syll, dims, hparams):\n",
    "    syll = np.squeeze(syll.reshape(dims))\n",
    "    # reshape spectrogram \n",
    "    if hparams['mel_filter']:\n",
    "        resize_shape = (int((np.shape(syll)[1]/hparams['resize_samp_fr']) * (1000/hparams['frame_shift_ms'])), hparams['num_freq_final'])\n",
    "        syll = np.array(Image.fromarray(np.squeeze(syll)).resize(resize_shape, Image.ANTIALIAS))\n",
    "        syll = np.dot(syll.T, mel_inversion_filter).T\n",
    "    else:\n",
    "        resize_shape = (int((np.shape(syll)[1]/hparams['resize_samp_fr']) * (1000/hparams['frame_shift_ms'])), hparams['num_freq'])\n",
    "        syll = np.array(Image.fromarray(np.squeeze(syll)).resize(resize_shape, Image.ANTIALIAS))\n",
    "    ### adding some noise tends to improve reconstruction quality\n",
    "    syll = rescale(syll, .25,1) +np.reshape(np.random.rand(np.prod(np.shape(syll)))*.25, np.shape(syll))\n",
    "    # invert spectrogram\n",
    "    waveform = sg.inv_spectrogram(rescale(syll, .25,1), hparams)\n",
    "    return waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:46:28.607358Z",
     "start_time": "2018-10-23T20:44:40.375977Z"
    }
   },
   "outputs": [],
   "source": [
    "invert_wavs = [invertSyllableToWav(i, dims, hparams) for i in tqdm(x_interp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-23T20:46:29.118205Z",
     "start_time": "2018-10-23T20:46:28.610568Z"
    }
   },
   "outputs": [],
   "source": [
    "# play back a sample of the song\n",
    "IPython.display.Audio(data=np.concatenate(invert_wavs), rate=hparams['sample_rate'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
