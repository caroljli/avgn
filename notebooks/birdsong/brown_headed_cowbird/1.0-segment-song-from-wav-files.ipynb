{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_set\"></a>\n",
    "# 1: Segmentation of WAVs\n",
    "\n",
    "The script reads each WAV file, finding periods of silence or noise, and segments rather than manually annotating the files.\n",
    "- Birdsong recordings are obtained by recording through the smart aviary (? <-- confirm this) chiefly developed by the Schmidt Lab at the University of Pennsylvania.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from glob import glob\n",
    "import re \n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports of local methods from the source code\n",
    "from avgn.segment_song.preprocessing import *\n",
    "import avgn.segment_song.preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output location of hdf5 files\n",
    "output_location = '../data/cb_wavs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and Analyze WAVs\n",
    "- Relative to each bird.\n",
    "- Input location found in ../data/cb_inputs/.\n",
    "- Output as an hdf5 file in cb_wavs.\n",
    "- Prints out dset structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must save recordings to ../data/cb_inputs\n",
    "# recordings can be found in data file in avgn\n",
    "input_loc = '../data/cb_inputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and specify file types when recordings are received'\n",
    "dsets = [(input_loc, 'cb' )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('../data/cb_inputs', 'cb')]\n"
     ]
    }
   ],
   "source": [
    "print(dsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47501519f9444a4938d78bba1c25ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-5528825392c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mwav_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnew_wavs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "wav_list = np.array([])\n",
    "dset_list = np.array([])\n",
    "for search_directory, dset in tqdm(dsets):\n",
    "    new_wavs = np.array(glob(search_directory))\n",
    "    dset_list = np.append(dset_list, [dset for i in range(len(new_wavs))])\n",
    "    print(dset_list)\n",
    "    wav_list = np.append(wav_list,new_wavs)\n",
    "    print(wav_list)\n",
    "print(wav_list[0], len(wav_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# organizes birds by name - unnamed waves (irrelvant?)\n",
    "# bird_names = [i.split('/')[6] for i in wav_list]\n",
    "# print(np.unique(bird_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create WAV Dataframe\n",
    "- Extract bird times and create the dataframe of the wavs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bir_xml_locs = glob(input_loc+'/*/Annotation.xml')\n",
    "bird_xml_locs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom parsing of an XML file to get wav time information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = pd.DataFrame(columns=['bird','WavLoc', 'WaveFileName','Position','Length', 'NumNote', 'NotePositions', 'NoteLengths', 'NoteLabels'])\n",
    "\n",
    "for bird_loc in tqdm(bird_xml_locs):\n",
    "    bird_xml = xml.etree.ElementTree.parse(bird_loc).getroot()\n",
    "    bird = bird_loc.split('/')[-2]\n",
    "    for element in tqdm(bird_xml.getchildren(), leave=False):\n",
    "        if element.tag == 'Sequence':\n",
    "            notePositions = []\n",
    "            noteLengths = []\n",
    "            noteLabels = []\n",
    "            for seq_element in element.getchildren():\n",
    "                if seq_element.tag == 'Position': position = seq_element.text\n",
    "                elif seq_element.tag == 'Length': length = seq_element.text\n",
    "                elif seq_element.tag == 'WaveFileName': WaveFileName = seq_element.text\n",
    "                elif seq_element.tag == 'NumNote': NumNote = seq_element.text\n",
    "                elif seq_element.tag == 'Note':\n",
    "                    for note_element in seq_element.getchildren():\n",
    "                        if note_element.tag == 'Label': noteLabels.append(note_element.text)\n",
    "                        elif note_element.tag == 'Position': notePositions.append(note_element.text)\n",
    "                        elif note_element.tag == 'Length': noteLengths.append(note_element.text)\n",
    "            song_df.loc[len(song_df)] = [bird, input_loc+bird+'/Wave/'+WaveFileName, WaveFileName, position, length, NumNote, notePositions, noteLengths, noteLabels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default date time method\n",
    "wav_times = []\n",
    "wav_loc = wav_list[0]\n",
    "n_no_date = 0\n",
    "for wav_file in wav_list:\n",
    "        dt = datetime(1900, 1, 1, 0, 0) + timedelta(hours=n_no_date)\n",
    "        n_no_date+=1\n",
    "        wav_times.append(dt)    \n",
    "wav_times = np.array(wav_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_times[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas dataframe corresponding to files, datetimes\n",
    "wav_df = pd.DataFrame.from_dict({'filename':wav_list,\n",
    "                                'wav_time': wav_times,\n",
    "                                'dset': dset_list,\n",
    "                                'birdname': bird_names})\n",
    "wav_df[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Vocalizations\n",
    "- Specific to brown-headed cowbirds.\n",
    "- **TODO: SET CUSTOM PARAMETERS!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {}\n",
    "param_dict['cb'] = {\n",
    "    ### Parameters ###\n",
    "    'lowcut': 0, # Hz # Low cut for our butter bandpass filter\n",
    "    'highcut': 15000, # Hz # High cut for our butter bandpass filter\n",
    "\n",
    "    'rms_window':  5, # seconds # the size of your window\n",
    "    'rms_stride': .01, # seconds # how big your step size should be for moving the filter\n",
    "    'noise_thresh': .01, # threshold percent of maximum noise to consider silence\n",
    "    'segment_padding': 4.0, # seconds to pad waveform extracted\n",
    "    'rms_padding': 1.0, #5.0, # seconds # how much to pad around vocalizations\n",
    "   \n",
    "    # filtering\n",
    "    'min_amp_val': 0, # the minimum value of a wav's amplitude to be considered containing any sound\n",
    "    'min_segment_length_s': 0, # How long a bout has to be to count\n",
    "    'max_segment_length_s': 10000.,  # If a bout is too long, dont count it\n",
    "    'min_silence_pct': 0.05,  # measure of noise in wav, by threshing the pct of time that the wav is silent\n",
    "\n",
    "    # FFT (we create a spectrogram here to filter out noise)\n",
    "    'num_freq':1024, # how many channels to use in a spectrogram \n",
    "    'sample_rate':44100, # what rate are your WAVs sampled at?\n",
    "    'preemphasis':0.97, \n",
    "    'ref_level_db':20, # reference db for computing spec\n",
    "    'frame_shift_ms':2, # step size for fft\n",
    "    'min_level_db': -50,# threshold for spectrograms (lower filters out more noise)\n",
    "    'max_power_f_min': 1000,# (HZ) If the maximum power of the spectral envelope is below this, call noise\n",
    "    'frame_shift_ms':40, # step size for fft\n",
    "    'frame_length_ms':40, # frame length for fft\n",
    "\n",
    "    # # Filter based upon power-frequency envelope\n",
    "    'vocal_freq_min' : 700,\n",
    "    'vocal_freq_max' : 15000\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of wav files found for each individual\n",
    "for (dset, bird), group in wav_df.groupby(('dset', 'birdname')):\n",
    "    print(dset, bird, len(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_created = True # whether to skip song that has already been processed\n",
    "parallel = False # whether to run this algorithm in parallel (across wav files)\n",
    "visualize = False # whether to output visualizations of spectrograms to the notebook screen - this is useful for setting parameters - you may also want to edit the code to visualized other aspects of the algorithm\n",
    "n_parallel = 10 # How many threads to run in parallel (if parallel == True)\n",
    "verbosity = 1 # how verbose to make the output of the parallelization (higher = more, 0 = none, >50 output is sent to std.out)\n",
    "verbose=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving WAVs\n",
    "- Saves to ''../data/cb_waves'.\n",
    "- Saves spectrogram PNGs to given folder to view segmentation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_folder = '../data/cb_wavs' # Where to save output wavs\n",
    "save_spectrograms = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soundsig.sound import BioSound \n",
    "from soundsig.sound import WavFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all wavs, \n",
    "# TODO: find way to group by birdname\n",
    "try:\n",
    "    key_list = ('wav_list', 'time_index', 'wav_file', 'wav_time', 'rate')\n",
    "    for (dset, bird), group in wav_df.groupby(('dset', 'birdname')):   \n",
    "\n",
    "        print('processing %s to save at %s' % (bird, save_to_folder))\n",
    "        bird_data = {key : [] for key in key_list}\n",
    "\n",
    "        print('total wavs: ', len(group)) \n",
    "\n",
    "        # create a spot to save the data\n",
    "        bird_folder = save_to_folder+bird+'/'\n",
    "        if not os.path.exists(bird_folder+'wavs/'):\n",
    "            os.makedirs(bird_folder+'wavs/') \n",
    "        if not os.path.exists(bird_folder+'csv/'):\n",
    "            os.makedirs(bird_folder+'csv/') \n",
    "\n",
    "        if parallel:\n",
    "            with Parallel(n_jobs=n_parallel, verbose=verbosity) as parallel:\n",
    "                parallel(delayed(pp.process_bird_wav)(bird, filename, wav_time, param_dict[dset],save_to_folder,\n",
    "                                                      visualize= visualize, skip_created= skip_created,\n",
    "                                                      save_spectrograms= save_spectrograms, verbose=verbose) \n",
    "                                                      for idx, gbird, gdset, filename, wav_time in tqdm(group.itertuples(),total=len(group)))\n",
    "        else:\n",
    "            for idx, gbird, gdset, filename, wav_time in tqdm(group.itertuples(), total=len(group)):\n",
    "                process_bird_wav(bird, filename, wav_time, param_dict[dset],save_to_folder, visualize=visualize,\n",
    "                                 skip_created=skip_created, save_spectrograms= save_spectrograms, verbose=verbose) \n",
    "except KeyboardInterrupt:\n",
    "    print('interrrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
